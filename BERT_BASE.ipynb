{"cells":[{"cell_type":"code","execution_count":1,"id":"b3d80130","metadata":{"id":"b3d80130","executionInfo":{"status":"ok","timestamp":1682530853839,"user_tz":-330,"elapsed":1002,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["import pandas as pd\n","import ast"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHV9MQy43Gwt","outputId":"81bc6811-43fb-4a08-e3fa-ccfe5a12502e","executionInfo":{"status":"ok","timestamp":1682530858836,"user_tz":-330,"elapsed":5004,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"id":"XHV9MQy43Gwt","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":3,"id":"f0e0dfb0","metadata":{"id":"f0e0dfb0","executionInfo":{"status":"ok","timestamp":1682530860502,"user_tz":-330,"elapsed":1674,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["import json\n","\n","with open('/content/drive/My Drive/MedNLI_Clinical_Inference/mli_train_v1.jsonl', 'r') as json_file:\n","    json_list_train = list(json_file)\n","\n","with open('/content/drive/My Drive/MedNLI_Clinical_Inference/mli_dev_v1.jsonl', 'r') as json_file:\n","    json_list_val = list(json_file)\n","\n","with open('/content/drive/My Drive/MedNLI_Clinical_Inference/mli_test_v1.jsonl', 'r') as json_file:\n","    json_list_test = list(json_file)"]},{"cell_type":"code","execution_count":4,"id":"0b06b6d8","metadata":{"id":"0b06b6d8","executionInfo":{"status":"ok","timestamp":1682530860504,"user_tz":-330,"elapsed":34,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["sent1_train = []\n","sent2_train = []\n","gl_train = []\n","\n","for i in range(len(json_list_train)):\n","    a = ast.literal_eval(json_list_train[i])\n","    sent1_train.append(a['sentence1'])\n","    sent2_train.append(a['sentence2'])\n","    gl_train.append(a['gold_label'])\n","\n","sent1_val = []\n","sent2_val = []\n","gl_val = []\n","\n","for i in range(len(json_list_val)):\n","    a = ast.literal_eval(json_list_val[i])\n","    sent1_val.append(a['sentence1'])\n","    sent2_val.append(a['sentence2'])\n","    gl_val.append(a['gold_label'])\n","\n","sent1_test = []\n","sent2_test = []\n","gl_test = []\n","\n","for i in range(len(json_list_test)):\n","    a = ast.literal_eval(json_list_test[i])\n","    sent1_test.append(a['sentence1'])\n","    sent2_test.append(a['sentence2'])\n","    gl_test.append(a['gold_label'])"]},{"cell_type":"code","execution_count":5,"id":"764c4bbc","metadata":{"id":"764c4bbc","executionInfo":{"status":"ok","timestamp":1682530860505,"user_tz":-330,"elapsed":33,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["data_train = pd.DataFrame()\n","data_train['sentence1'] = sent1_train\n","data_train['sentence2'] = sent2_train\n","data_train['gold_label'] = gl_train\n","\n","data_val = pd.DataFrame()\n","data_val['sentence1'] = sent1_val\n","data_val['sentence2'] = sent2_val\n","data_val['gold_label'] = gl_val\n","\n","data_test = pd.DataFrame()\n","data_test['sentence1'] = sent1_test\n","data_test['sentence2'] = sent2_test\n","data_test['gold_label'] = gl_test"]},{"cell_type":"code","execution_count":6,"id":"aa20fdac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aa20fdac","outputId":"89eb35ed-28de-4daf-b140-2a797e126f42","executionInfo":{"status":"ok","timestamp":1682530860507,"user_tz":-330,"elapsed":33,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 11232 entries, 0 to 11231\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   sentence1   11232 non-null  object\n"," 1   sentence2   11232 non-null  object\n"," 2   gold_label  11232 non-null  object\n","dtypes: object(3)\n","memory usage: 263.4+ KB\n","None\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1395 entries, 0 to 1394\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   sentence1   1395 non-null   object\n"," 1   sentence2   1395 non-null   object\n"," 2   gold_label  1395 non-null   object\n","dtypes: object(3)\n","memory usage: 32.8+ KB\n","None\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1422 entries, 0 to 1421\n","Data columns (total 3 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   sentence1   1422 non-null   object\n"," 1   sentence2   1422 non-null   object\n"," 2   gold_label  1422 non-null   object\n","dtypes: object(3)\n","memory usage: 33.5+ KB\n","None\n"]}],"source":["print(data_train.info())\n","print(data_val.info())\n","print(data_test.info())"]},{"cell_type":"code","execution_count":7,"id":"2bd52d67","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"2bd52d67","outputId":"defef872-160f-47d6-f878-2f66687ebed9","executionInfo":{"status":"ok","timestamp":1682530860508,"user_tz":-330,"elapsed":30,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["entailment       0.333333\n","contradiction    0.333333\n","neutral          0.333333\n","Name: gold_label, dtype: float64"]},"metadata":{},"execution_count":7}],"source":["data_train['gold_label'].value_counts(normalize = True)"]},{"cell_type":"code","execution_count":8,"id":"3a9298b4","metadata":{"id":"3a9298b4","executionInfo":{"status":"ok","timestamp":1682530860509,"user_tz":-330,"elapsed":23,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["data_train['combined_sent'] = data_train['sentence1']+ data_train['sentence2']\n","data_val['combined_sent'] = data_val['sentence1']+ data_val['sentence2']\n","data_test['combined_sent'] = data_test['sentence1']+ data_test['sentence2']"]},{"cell_type":"code","execution_count":9,"id":"cc594ed6","metadata":{"scrolled":true,"id":"cc594ed6","executionInfo":{"status":"ok","timestamp":1682530860510,"user_tz":-330,"elapsed":22,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","le = LabelEncoder()\n","\n","data_train['gold_label'] = le.fit_transform(data_train['gold_label'])\n","data_train['gold_label'] = data_train['gold_label'].astype('int64')\n","\n","data_val['gold_label'] = le.fit_transform(data_val['gold_label'])\n","data_val['gold_label'] = data_val['gold_label'].astype('int64')\n","\n","data_test['gold_label'] = le.fit_transform(data_test['gold_label'])\n","data_test['gold_label'] = data_test['gold_label'].astype('int64')\n"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xlm0PzGj8W6a","outputId":"9d8f2d89-b826-4439-ad19-bc197cabb38d","executionInfo":{"status":"ok","timestamp":1682530864611,"user_tz":-330,"elapsed":4121,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"id":"Xlm0PzGj8W6a","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n"]}]},{"cell_type":"code","execution_count":11,"id":"6ac1f174","metadata":{"id":"6ac1f174","executionInfo":{"status":"ok","timestamp":1682530866926,"user_tz":-330,"elapsed":2326,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["import time\n","import torch\n","import torch.nn.functional as F\n","import torchtext\n","\n","from transformers import BertTokenizer, BertModel"]},{"cell_type":"code","execution_count":12,"id":"5771b050","metadata":{"id":"5771b050","executionInfo":{"status":"ok","timestamp":1682530866928,"user_tz":-330,"elapsed":15,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["torch.backends.cudnn.deterministic = True\n","RANDOM_SEED = 123\n","torch.manual_seed(RANDOM_SEED)\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","NUM_EPOCHS = 5"]},{"cell_type":"code","execution_count":13,"id":"51315bc5","metadata":{"id":"51315bc5","executionInfo":{"status":"ok","timestamp":1682530866929,"user_tz":-330,"elapsed":13,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["train_texts = data_train.iloc[:]['combined_sent'].values\n","train_labels = data_train.iloc[:]['gold_label'].values\n","\n","valid_texts = data_val.iloc[:]['combined_sent'].values\n","valid_labels = data_val.iloc[:]['gold_label'].values\n","\n","\n","test_texts = data_test.iloc[:]['combined_sent'].values\n","test_labels = data_test.iloc[:]['gold_label'].values"]},{"cell_type":"code","execution_count":14,"id":"19eac470","metadata":{"id":"19eac470","executionInfo":{"status":"ok","timestamp":1682530875960,"user_tz":-330,"elapsed":9042,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n","valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True)\n","test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"]},{"cell_type":"code","execution_count":15,"id":"d7421fe0","metadata":{"id":"d7421fe0","executionInfo":{"status":"ok","timestamp":1682530875961,"user_tz":-330,"elapsed":16,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["class MedNLIDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","\n","train_dataset = MedNLIDataset(train_encodings, train_labels)\n","valid_dataset = MedNLIDataset(valid_encodings, valid_labels)\n","test_dataset = MedNLIDataset(test_encodings, test_labels)"]},{"cell_type":"code","execution_count":16,"id":"c33e4b03","metadata":{"id":"c33e4b03","executionInfo":{"status":"ok","timestamp":1682530875963,"user_tz":-330,"elapsed":15,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=16, shuffle=False)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":17,"id":"a2da756c","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"a2da756c","outputId":"24b02d8c-0a6a-4a81-eba8-2e16aad83a74","executionInfo":{"status":"ok","timestamp":1682530880095,"user_tz":-330,"elapsed":915,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["model = BertModel.from_pretrained('bert-base-uncased', num_labels=3)\n","model.to(DEVICE)\n","model.train()\n","\n","optim = torch.optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":18,"id":"1379faaf","metadata":{"id":"1379faaf","executionInfo":{"status":"ok","timestamp":1682530880096,"user_tz":-330,"elapsed":18,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":["def compute_accuracy(model, data_loader, device):\n","\n","    with torch.no_grad():\n","\n","        correct_pred, num_examples = 0, 0\n","\n","        for batch_idx, batch in enumerate(data_loader):\n","\n","            ### Prepare data\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","            \n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss, logits = outputs['loss'], outputs['logits']\n","\n","            _, predicted_labels = torch.max(logits, 1)\n","\n","            num_examples += labels.size(0)\n","\n","            correct_pred += (predicted_labels == labels).sum()\n","    return correct_pred.float()/num_examples * 100"]},{"cell_type":"code","execution_count":19,"id":"aa17b1bc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"aa17b1bc","outputId":"c09f8617-2ac1-4751-bf5c-097b2078de8c","executionInfo":{"status":"error","timestamp":1682530880844,"user_tz":-330,"elapsed":765,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-e67e36eac943>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m### Forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'labels'"]}],"source":["start_time = time.time()\n","\n","for epoch in range(NUM_EPOCHS):\n","    \n","    model.train()\n","    \n","    for batch_idx, batch in enumerate(train_loader):\n","        \n","        ### Prepare data\n","        input_ids = batch['input_ids'].to(DEVICE)\n","        attention_mask = batch['attention_mask'].to(DEVICE)\n","        labels = batch['labels'].to(DEVICE)\n","\n","        ### Forward\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss, logits = outputs['loss'], outputs['logits']\n","        \n","        ### Backward\n","        optim.zero_grad()\n","        loss.backward()\n","        optim.step()\n","        \n","        ### Logging\n","        if not batch_idx % 30:\n","            print (f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n","                   f'Batch {batch_idx:04d}/{len(train_loader):04d} | '\n","                   f'Loss: {loss:.4f}')\n","            \n","    model.eval()\n","\n","    with torch.set_grad_enabled(False):\n","        print(f'training accuracy: '\n","              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n","              f'\\nvalid accuracy: '\n","              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n","        \n","    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n","    \n","print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n","print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"]},{"cell_type":"code","execution_count":null,"id":"6ffcdd64","metadata":{"id":"6ffcdd64","executionInfo":{"status":"aborted","timestamp":1682530880845,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rekha Regar","userId":"12480255521118245703"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}