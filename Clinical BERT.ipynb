{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3d80130",
      "metadata": {
        "id": "b3d80130"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHV9MQy43Gwt",
        "outputId": "a76b3872-2673-4df0-e454-b2c618f58aae"
      },
      "id": "XHV9MQy43Gwt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e0dfb0",
      "metadata": {
        "id": "f0e0dfb0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('/content/drive/My Drive/MedNLI_Clinical_Inference/mli_train_v1.jsonl', 'r') as json_file:\n",
        "    json_list_train = list(json_file)\n",
        "\n",
        "with open('/content/drive/My Drive/MedNLI_Clinical_Inference/mli_dev_v1.jsonl', 'r') as json_file:\n",
        "    json_list_val = list(json_file)\n",
        "\n",
        "with open('/content/drive/My Drive/MedNLI_Clinical_Inference/mli_test_v1.jsonl', 'r') as json_file:\n",
        "    json_list_test = list(json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b06b6d8",
      "metadata": {
        "id": "0b06b6d8"
      },
      "outputs": [],
      "source": [
        "sent1_train = []\n",
        "sent2_train = []\n",
        "gl_train = []\n",
        "\n",
        "for i in range(len(json_list_train)):\n",
        "    a = ast.literal_eval(json_list_train[i])\n",
        "    sent1_train.append(a['sentence1'])\n",
        "    sent2_train.append(a['sentence2'])\n",
        "    gl_train.append(a['gold_label'])\n",
        "\n",
        "sent1_val = []\n",
        "sent2_val = []\n",
        "gl_val = []\n",
        "\n",
        "for i in range(len(json_list_val)):\n",
        "    a = ast.literal_eval(json_list_val[i])\n",
        "    sent1_val.append(a['sentence1'])\n",
        "    sent2_val.append(a['sentence2'])\n",
        "    gl_val.append(a['gold_label'])\n",
        "\n",
        "sent1_test = []\n",
        "sent2_test = []\n",
        "gl_test = []\n",
        "\n",
        "for i in range(len(json_list_test)):\n",
        "    a = ast.literal_eval(json_list_test[i])\n",
        "    sent1_test.append(a['sentence1'])\n",
        "    sent2_test.append(a['sentence2'])\n",
        "    gl_test.append(a['gold_label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "764c4bbc",
      "metadata": {
        "id": "764c4bbc"
      },
      "outputs": [],
      "source": [
        "data_train = pd.DataFrame()\n",
        "data_train['sentence1'] = sent1_train\n",
        "data_train['sentence2'] = sent2_train\n",
        "data_train['gold_label'] = gl_train\n",
        "\n",
        "data_val = pd.DataFrame()\n",
        "data_val['sentence1'] = sent1_val\n",
        "data_val['sentence2'] = sent2_val\n",
        "data_val['gold_label'] = gl_val\n",
        "\n",
        "data_test = pd.DataFrame()\n",
        "data_test['sentence1'] = sent1_test\n",
        "data_test['sentence2'] = sent2_test\n",
        "data_test['gold_label'] = gl_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa20fdac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa20fdac",
        "outputId": "de88968c-c744-4307-9686-fea1b6af0d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 11232 entries, 0 to 11231\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   sentence1   11232 non-null  object\n",
            " 1   sentence2   11232 non-null  object\n",
            " 2   gold_label  11232 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 263.4+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1395 entries, 0 to 1394\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   sentence1   1395 non-null   object\n",
            " 1   sentence2   1395 non-null   object\n",
            " 2   gold_label  1395 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 32.8+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1422 entries, 0 to 1421\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   sentence1   1422 non-null   object\n",
            " 1   sentence2   1422 non-null   object\n",
            " 2   gold_label  1422 non-null   object\n",
            "dtypes: object(3)\n",
            "memory usage: 33.5+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(data_train.info())\n",
        "print(data_val.info())\n",
        "print(data_test.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd52d67",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bd52d67",
        "outputId": "df334de8-f3ff-4273-e618-8c1abe90a949"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "entailment       0.333333\n",
              "contradiction    0.333333\n",
              "neutral          0.333333\n",
              "Name: gold_label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data_train['gold_label'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a9298b4",
      "metadata": {
        "id": "3a9298b4"
      },
      "outputs": [],
      "source": [
        "data_train['combined_sent'] = data_train['sentence1']+ data_train['sentence2']\n",
        "data_val['combined_sent'] = data_val['sentence1']+ data_val['sentence2']\n",
        "data_test['combined_sent'] = data_test['sentence1']+ data_test['sentence2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc594ed6",
      "metadata": {
        "scrolled": true,
        "id": "cc594ed6"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "data_train['gold_label'] = le.fit_transform(data_train['gold_label'])\n",
        "data_train['gold_label'] = data_train['gold_label'].astype('int64')\n",
        "\n",
        "data_val['gold_label'] = le.fit_transform(data_val['gold_label'])\n",
        "data_val['gold_label'] = data_val['gold_label'].astype('int64')\n",
        "\n",
        "data_test['gold_label'] = le.fit_transform(data_test['gold_label'])\n",
        "data_test['gold_label'] = data_test['gold_label'].astype('int64')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xlm0PzGj8W6a",
        "outputId": "94ca2ae1-029c-44b7-f31a-796863c99c84"
      },
      "id": "Xlm0PzGj8W6a",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ac1f174",
      "metadata": {
        "id": "6ac1f174"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "\n",
        "import transformers\n",
        "from transformers import DistilBertTokenizerFast\n",
        "from transformers import DistilBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5771b050",
      "metadata": {
        "id": "5771b050"
      },
      "outputs": [],
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "NUM_EPOCHS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51315bc5",
      "metadata": {
        "id": "51315bc5"
      },
      "outputs": [],
      "source": [
        "train_texts = data_train.iloc[:]['combined_sent'].values\n",
        "train_labels = data_train.iloc[:]['gold_label'].values\n",
        "\n",
        "valid_texts = data_val.iloc[:]['combined_sent'].values\n",
        "valid_labels = data_val.iloc[:]['gold_label'].values\n",
        "\n",
        "\n",
        "test_texts = data_test.iloc[:]['combined_sent'].values\n",
        "test_labels = data_test.iloc[:]['gold_label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19eac470",
      "metadata": {
        "id": "19eac470"
      },
      "outputs": [],
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "valid_encodings = tokenizer(list(valid_texts), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7421fe0",
      "metadata": {
        "id": "d7421fe0"
      },
      "outputs": [],
      "source": [
        "class MedNLIDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "train_dataset = MedNLIDataset(train_encodings, train_labels)\n",
        "valid_dataset = MedNLIDataset(valid_encodings, valid_labels)\n",
        "test_dataset = MedNLIDataset(test_encodings, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c33e4b03",
      "metadata": {
        "id": "c33e4b03"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2da756c",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2da756c",
        "outputId": "692ee74e-b7fc-405a-80f3-f9075efc888a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\n",
        "model.to(DEVICE)\n",
        "model.train()\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1379faaf",
      "metadata": {
        "id": "1379faaf"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(data_loader):\n",
        "\n",
        "            ### Prepare data\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss, logits = outputs['loss'], outputs['logits']\n",
        "\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += labels.size(0)\n",
        "\n",
        "            correct_pred += (predicted_labels == labels).sum()\n",
        "    return correct_pred.float()/num_examples * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa17b1bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa17b1bc",
        "outputId": "8209ffc5-84f0-4576-f396-92b90c1ab65f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001/0005 | Batch 0000/0351 | Loss: 1.1013\n",
            "Epoch: 0001/0005 | Batch 0030/0351 | Loss: 1.0307\n",
            "Epoch: 0001/0005 | Batch 0060/0351 | Loss: 0.8365\n",
            "Epoch: 0001/0005 | Batch 0090/0351 | Loss: 0.7707\n",
            "Epoch: 0001/0005 | Batch 0120/0351 | Loss: 0.7100\n",
            "Epoch: 0001/0005 | Batch 0150/0351 | Loss: 0.5918\n",
            "Epoch: 0001/0005 | Batch 0180/0351 | Loss: 0.9455\n",
            "Epoch: 0001/0005 | Batch 0210/0351 | Loss: 0.7963\n",
            "Epoch: 0001/0005 | Batch 0240/0351 | Loss: 0.7874\n",
            "Epoch: 0001/0005 | Batch 0270/0351 | Loss: 0.6973\n",
            "Epoch: 0001/0005 | Batch 0300/0351 | Loss: 0.6928\n",
            "Epoch: 0001/0005 | Batch 0330/0351 | Loss: 0.8079\n",
            "training accuracy: 77.52%\n",
            "valid accuracy: 71.90%\n",
            "Time elapsed: 9.29 min\n",
            "Epoch: 0002/0005 | Batch 0000/0351 | Loss: 0.5562\n",
            "Epoch: 0002/0005 | Batch 0030/0351 | Loss: 0.8095\n",
            "Epoch: 0002/0005 | Batch 0060/0351 | Loss: 0.4443\n",
            "Epoch: 0002/0005 | Batch 0090/0351 | Loss: 0.5540\n",
            "Epoch: 0002/0005 | Batch 0120/0351 | Loss: 0.4853\n",
            "Epoch: 0002/0005 | Batch 0150/0351 | Loss: 0.4161\n",
            "Epoch: 0002/0005 | Batch 0180/0351 | Loss: 0.6563\n",
            "Epoch: 0002/0005 | Batch 0210/0351 | Loss: 0.5750\n",
            "Epoch: 0002/0005 | Batch 0240/0351 | Loss: 0.7714\n",
            "Epoch: 0002/0005 | Batch 0270/0351 | Loss: 0.4242\n",
            "Epoch: 0002/0005 | Batch 0300/0351 | Loss: 0.4595\n",
            "Epoch: 0002/0005 | Batch 0330/0351 | Loss: 0.6585\n",
            "training accuracy: 85.75%\n",
            "valid accuracy: 74.27%\n",
            "Time elapsed: 18.58 min\n",
            "Epoch: 0003/0005 | Batch 0000/0351 | Loss: 0.3848\n",
            "Epoch: 0003/0005 | Batch 0030/0351 | Loss: 0.4046\n",
            "Epoch: 0003/0005 | Batch 0060/0351 | Loss: 0.2987\n",
            "Epoch: 0003/0005 | Batch 0090/0351 | Loss: 0.4753\n",
            "Epoch: 0003/0005 | Batch 0120/0351 | Loss: 0.3029\n",
            "Epoch: 0003/0005 | Batch 0150/0351 | Loss: 0.4401\n",
            "Epoch: 0003/0005 | Batch 0180/0351 | Loss: 0.7785\n",
            "Epoch: 0003/0005 | Batch 0210/0351 | Loss: 0.4655\n",
            "Epoch: 0003/0005 | Batch 0240/0351 | Loss: 0.3120\n",
            "Epoch: 0003/0005 | Batch 0270/0351 | Loss: 0.5353\n",
            "Epoch: 0003/0005 | Batch 0300/0351 | Loss: 0.3732\n",
            "Epoch: 0003/0005 | Batch 0330/0351 | Loss: 0.4920\n",
            "training accuracy: 91.44%\n",
            "valid accuracy: 75.77%\n",
            "Time elapsed: 27.86 min\n",
            "Epoch: 0004/0005 | Batch 0000/0351 | Loss: 0.1564\n",
            "Epoch: 0004/0005 | Batch 0030/0351 | Loss: 0.1306\n",
            "Epoch: 0004/0005 | Batch 0060/0351 | Loss: 0.1843\n",
            "Epoch: 0004/0005 | Batch 0090/0351 | Loss: 0.1198\n",
            "Epoch: 0004/0005 | Batch 0120/0351 | Loss: 0.3150\n",
            "Epoch: 0004/0005 | Batch 0150/0351 | Loss: 0.1003\n",
            "Epoch: 0004/0005 | Batch 0180/0351 | Loss: 0.1254\n",
            "Epoch: 0004/0005 | Batch 0210/0351 | Loss: 0.2470\n",
            "Epoch: 0004/0005 | Batch 0240/0351 | Loss: 0.3041\n",
            "Epoch: 0004/0005 | Batch 0270/0351 | Loss: 0.2690\n",
            "Epoch: 0004/0005 | Batch 0300/0351 | Loss: 0.3729\n",
            "Epoch: 0004/0005 | Batch 0330/0351 | Loss: 0.4810\n",
            "training accuracy: 95.23%\n",
            "valid accuracy: 76.42%\n",
            "Time elapsed: 37.15 min\n",
            "Epoch: 0005/0005 | Batch 0000/0351 | Loss: 0.1093\n",
            "Epoch: 0005/0005 | Batch 0030/0351 | Loss: 0.1489\n",
            "Epoch: 0005/0005 | Batch 0060/0351 | Loss: 0.0872\n",
            "Epoch: 0005/0005 | Batch 0090/0351 | Loss: 0.1076\n",
            "Epoch: 0005/0005 | Batch 0120/0351 | Loss: 0.1409\n",
            "Epoch: 0005/0005 | Batch 0150/0351 | Loss: 0.2743\n",
            "Epoch: 0005/0005 | Batch 0180/0351 | Loss: 0.3992\n",
            "Epoch: 0005/0005 | Batch 0210/0351 | Loss: 0.1576\n",
            "Epoch: 0005/0005 | Batch 0240/0351 | Loss: 0.2019\n",
            "Epoch: 0005/0005 | Batch 0270/0351 | Loss: 0.2698\n",
            "Epoch: 0005/0005 | Batch 0300/0351 | Loss: 0.1834\n",
            "Epoch: 0005/0005 | Batch 0330/0351 | Loss: 0.1359\n",
            "training accuracy: 96.74%\n",
            "valid accuracy: 75.56%\n",
            "Time elapsed: 46.41 min\n",
            "Total Training Time: 46.41 min\n",
            "Test accuracy: 76.30%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "\n",
        "        ### Prepare data\n",
        "        input_ids = batch['input_ids'].to(DEVICE)\n",
        "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "        labels = batch['labels'].to(DEVICE)\n",
        "\n",
        "        ### Forward\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss, logits = outputs['loss'], outputs['logits']\n",
        "\n",
        "        ### Backward\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        ### Logging\n",
        "        if not batch_idx % 30:\n",
        "            print (f'Epoch: {epoch+1:04d}/{NUM_EPOCHS:04d} | '\n",
        "                   f'Batch {batch_idx:04d}/{len(train_loader):04d} | '\n",
        "                   f'Loss: {loss:.4f}')\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'training accuracy: '\n",
        "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
        "              f'\\nvalid accuracy: '\n",
        "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
        "\n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "\n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ffcdd64",
      "metadata": {
        "id": "6ffcdd64"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}